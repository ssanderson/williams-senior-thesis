\documentclass[twoside]{article}
\setlength{\oddsidemargin}{0.25 in}
\setlength{\evensidemargin}{-0.25 in}
\setlength{\topmargin}{-0.6 in}
\setlength{\textwidth}{6.5 in}
\setlength{\textheight}{8.5 in}
\setlength{\headsep}{0.75 in}
\setlength{\parindent}{0 in}
\setlength{\parskip}{0.1 in}

\setcounter{secnumdepth}{2}

%
% ADD PACKAGES here:
%
\usepackage{amsmath,amsfonts,graphicx}

\renewcommand{\thepage}{\arabic{page}}
\renewcommand{\thesection}{\arabic{section}}
\renewcommand{\theequation}{\arabic{equation}}
\renewcommand{\thefigure}{\arabic{figure}}
\renewcommand{\thetable}{\arabic{table}}

%
% The following macro is used to generate the header.
%
\newcommand{\head}[2]{
   \pagestyle{myheadings}
   \thispagestyle{plain}
   \newpage
   \noindent
   \begin{center}
   \framebox{
      \vbox{\vspace{2mm}
    \hbox to 6.28in { {\bf Scott Sanderson
		\hfill Source: \cite{#1} }}
       \vspace{4mm}
       \hbox to 6.28in { {\Large \hfill #2 \hfill} }
       \vspace{2mm}
       \hbox to 6.28in { { \hfill Date: \today} }
      \vspace{2mm}}
   }
   \end{center}
   
   \vspace*{4mm}
}

% Thesis Commands
\usepackage{thesiscommands}

% Convention for citations is authors' initials followed by the year.
% For example, to cite a paper by Leighton and Maggs you would type
% \cite{LM89}, and to cite a paper by Strassen you would type
% \cite{S69}.  (To avoid bibliography problems, for now we redefine
% the \cite command.)  Also commands that create a suitable format for
% the reference list.

\renewcommand{\cite}[1]{[#1]}
\def\beginrefs{\begin{list}%
        {[\arabic{equation}]}{\usecounter{equation}
         \setlength{\leftmargin}{2.0truecm}\setlength{\labelsep}{0.4truecm}%
         \setlength{\labelwidth}{1.6truecm}}}
\def\endrefs{\end{list}}
\def\bibentry#1{\item[\hbox{[#1]}]}


%Use this command for a figure; it puts a figure in wherever you want it.
%usage: \fig{NUMBER}{SPACE-IN-INCHES}{CAPTION}
\newcommand{\fig}[3]{
			\vspace{#2}
			\begin{center}
			Figure \thelecnum.#1:~#3
			\end{center}
	}
% Use these for theorems, lemmas, proofs, etc.
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{claim}{Claim}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{definition}{Definition}[section]
\newenvironment{proof}{{\bf Proof:}}{\hfill\rule{2mm}{2mm}}
\newenvironment{proofsketch}{{\bf Proof Sketch:}}{\hfill\rule{2mm}{2mm}}

\begin{document}
%FILL IN THE RIGHT INFO.
%\head{**Title**}{**Date**}
\head{B98}{Chap 2 - Definitions and First Properties of Computation}

\section{A Finite Dimensional Model of Computation}

The basic idea that we want to formalize with a Finite Dimensional
Machine is that of an algorithm over a ring that consists in
repeatedly iterating a set of polynomial functions over elements of
the ring.  The canonical motivating example is Newton's Method over
$\reals^2$, which approximates the zeros of an arbitrary polynomial by
repeatedly calculating an associated polynomial function on a start
value until the resulting value is less than some $\epsilon$ (and thus
presumably close to a zero of the polynomial).  The key elements of
such an algorithm are:

\begin{enumerate}
\item A set of inputs over which the algorithm is defined.
  
\item A set of values that can be stored by the algorithm for
  future computations.
  
\item A function (or set of functions) to perform calculations on the
  stored values.
  
\item A decision function (or set of decision functions) to determine
  which calculation to perform at a given step.
  
\item A set of values for the algorithm to output.
\end{enumerate}

We present two equivalent definitions of a Finite Dimensional Machine.
The first is nearly a direct transcription of the definition given by
\cite{B98}.  The second is a version which replaces the directed graph
in the first definition with a specification of what Blum et al. call
the computing endomorphism.  The primary motivation behind this change
is to facilitate a more natural extension to the non-deterministic
case.

\subsection{Definitions}

Let $R$ be a commutative ring with unit, and let $l, m, n$ be positive
integers.  By convention, we use the letter $p$ to denote a polynomial
over $R$, and we denote the ring of polynomials over $R$ of degree $k$
by $R^k$. 

\begin{definition}{\textbf{Finite Dimensional Machine} over a ring
    \textbf{R} (as defined in \cite{B98})}
  
  A \textbf{Finite Dimensional Machine} (FDM), $M$ over $R$ is a
  finite, directed, connected graph with four types of nodes:
  \emph{input, computation, branch} and \emph{output}.  An FDM has one
  input and one output node, but can have any number of branch and
  computation nodes. The input node has indegree 0.  All other nodes
  have indegree $\geq$ 1. The input node and computation nodes have
  outdegree 1; branch nodes have outdegree 2, and the output node has
  outdegree 0.  We will use the expression ``next node(s)'' of a node
  $\beta$ to refer to the node(s) to which $\beta$ has outgoing edges.\\
  
  \emph{\note{Blum et al. allow a machine to have multiple
      output nodes, but it is relatively easy to show that any machine
      with multiple output nodes can be trivially reduced to a machine
      with a single output node, so for ease of notation we
      prefer the single output notation here.}}\\
  
  An FDM also has three associated spaces: an input space $\inspace_M
  \subseteq R^n$, a state space $\statespace_M \subseteq R^m$, and an
  output space $\outspace_M \subseteq R^l$.  (Recall that $R^k$
  denotes the ring of polynomials over $R$ with degree at most $k$).\\
  
  Each node has an associated map, which varies in structure in
  accordance with its type.
  \begin{enumerate}
  \item Associated with the input node is a linear map
    \functype{I}{\inspace_M}{\statespace_M}. We denote the next node
    of the input node by $\beta_1$.
    
  \item Associated with each computation node, $\eta$, is a polynomial
    map \functype{g_\eta}{\statespace_M}{\statespace_M}. We denote the
    next node of $\eta$ by $\beta_\eta$.
    
  \item Associated with each branch node, $b$ is a nonzero polynomial
    function \functype{g_b}{\statespace_M}{R}.  We associate the
    condition $g_b(p) \geq 0$ with one of the next nodes of $b$,
    called the \textbf{Yes Node} of $b$.  We symbolically denote the
    Yes Node by $\beta_b^+$. We associate the condition $g_b(p) < 0$
    with the remaining next node of $b$, which we call the \textbf{No
      Node} and denote $\beta_b^-$.
    
  \item Associated with the output node is a linear map
    \functype{O}{\statespace_M}{\outspace_M}.
    
  \end{enumerate}
\end{definition}

Blum et al's definition is meant to capture an intuition that a real
algorithm can essentially be described by a flowchart.  On this model,
computation consists in following the arrows of the flowchart from
node to node, performing computations and storing their values.  One
drawback of their formulation is that it does not easily generalize to
a non-deterministic formulation.  In particular, because their
definition of a machine is explicitly associated with a particular
graph, it is awkward to abstract a notion of being in multiple
locations simultaneously.  The following definition is meant to be
equivalent in computational power to that of Blum et al., while also
allowing a more natural generalization to incorporating nondeterminism.

\begin{definition}{\textbf{Finite Dimensional Machine} over a ring \textbf{R}}
  
  A \textbf{Finite Dimensional Machine} (FDM) over $R$ is a tuple,
  $(\inspace, \statespace, \outspace, \nodes, H, H_{in}, H_{out})$, where:
  
  \begin{enumerate}

  \item $\inspace \subseteq R^l$ is the \textbf{Input Space} of M.

  \item $\statespace \subseteq R^m$ is the \textbf{State Space} of M.

  \item $\outspace \subseteq R^n$ is the \textbf{Output Space} of M.

  \item $\nodes$ is a finite set of nodes given by: $ \nodes =
    \set{\nodein, \nodeout} \cup \set{\eta_1, \eta_2, \ldots \eta_i}
    \cup \set{b_1, b_2, \ldots b_j}$, where $\nodes_{in}$ is the
    unique \textbf{Input Node}, $\nodeout$ is the unique
    \textbf{Output Node}, $\set{\eta_1, \eta_2, \ldots \eta_i}$ is the
    set of \textbf{Computation Nodes}, and $ \set{b_1, b_2, \ldots b_j}$
    is the set of \textbf{Branching Nodes}.

  \item \functype{H_{in}}{\inspace}{\nodein \times \statespace} is a
    linear map called the \textbf{Input Map} of $M$.

  \item \functype{H}{\nodes \times \statespace}{\nodes \times
      \statespace} is the \textbf{Computing Endomorphism} of $M$.
    
  \item \functype{H_{out}}{\nodeout \times \statespace}{\outspace} is
    a linear map called the \textbf{Output Map} of $M$.
    
  \end{enumerate}
  
\end{definition}

\note{By convention, we use the symbol $\beta$ to refer to a node when
  we do not wish to distinguish between types.}

\subsubsection{Properties of the computing endomorphism $H$}

The computing endomorphism abstracts the process of either
performing a computation on our currently stored information or
making a decision about which computation to perform next.  Each
computation node in $\nodes$ represents a state of our algorithm in
which we want to perform a specific computation.  Each branching
node represents a state in which we need to decide which computation
to perform next.  Since each computation node represents a specific
computation and each branching node represents a specific decision
procedure, we add the following restrictions to $H$:

\begin{enumerate}
  
\item For each computation node, $\eta$, there exists a unique node,
  $\beta_\eta$ and a polynomial map
  \functype{g_\eta}{\statespace}{\statespace}, such that $H(\eta, p)
  = (\beta_\eta, g_\eta(p)) \mid \forall p \in \statespace$.  We
  refer to $g_\eta$ as the \textbf{Computation Map} of $\eta$.
  
\item For each branch node, $b$, there exists a pair of nodes,
  $\beta_b^+$ and $\beta_b^-$, and a non-zero polynomial map,
  \functype{g_b}{\statespace}{R}, such that $H(b, p) = (\beta_b^+,
  p)$ if $g_b \geq 0$ and $H(b,p) = (\beta_b^-, p)$ if $g_b < 0$.
  We refer to $g_b$ as the \textbf{Branching Function} of $b$, and
  we refer to $\beta_b^+$ and $\beta_b^-$ respectively as the
  \textbf{Yes Node} and \textbf{No Node} of $b$.
  
\end{enumerate}

We are now in a position to define what it means for a machine $M$
to perform a computation on some input, $p$.  The basic idea is that a 
computation is a path through $\nodes \times \statespace$, that begins
with $I_M(p)$ and follows the computing endomorphism of $M$, halting upon
reaching the output node of $M$.  The ``run time'' of a computation becomes
the length of this path, and the halting set of a $M$ becomes the set of input
values with computations of finite length.

\begin{definition}{\textbf{Computation, Halting Set, and Computation Map}}\\
  
  The \textbf{Computation}, $\compute_p$, performed by an FDM, $M$,
  on input $p \in \inspace$ is the sequence: 
  $$z^0, z^1, z^2, \ldots z^k, \ldots$$ 
  where\\ 
  \centerline{$z^0 = (H_{in}(p))$, $z^1$ = $H(z^0)$, $z^2 = H(z^1) \ldots$, $z^k = H(z^{k-1})$}\\

  A computation is said to \textbf{halt} if there exists an integer
  $T$ such that $z^T = (\nodeout, s)$ for some $s \in \statespace$.
  In such a case, the finite sequence $\compute_p = z^0, z^1, \ldots
  z^T$ is said to be a \textbf{halting computation} with
  \textbf{halting time} $T_M(p) = T$, and we define the \textbf{output
    value} of $\compute_p$ to be $\computeout{p} = H_{out}(z^T)$.  If
  $\compute_p$ is not a halting computation, $\computeout{p}$ is
  undefined, and we say that $T_M(p) = \infty$.\\
  
  \todo{I find a lot of the time-T notation confusing and/or
    ambiguous. Maybe standardize to always use T as a function
    argument?}

  The \textbf{Halting Set}, $\halting_M \subseteq \inspace$ of an FDM,
  $M$ is the set: 
  $$\set{p \in \inspace \mid \compute_p \text{ is a halting computation}}$$.\\
  \noindent The \textbf{time-T Halting Set} of $M$, $\halting_T$ is given by:
  $$p \mid p \in \halting_M, T_M(p) \leq T$$.
  
  The \textbf{Computation Function} or \textbf{Input/Output Map} of
  $M$ \functype{\computefn}{\halting_M}{\outspace_M} is given by:
  $$\computefn(p) = \computeout{p}$$.
\end{definition}
\begin{definition}{\textbf{Computation Path} and \textbf{State Trajectory}}\\
  
  The \textbf{Computation Path}, $\computepath_p$, of $M$ on
  input $p$ is the projection of $\compute_p$ under the map:
  $$\mfunctype{\pathprojection}{\fullstate}{\nodes} \mid \pathprojection(\beta, p) = \beta$$
  
  The \textbf{State Trajectory} of an FDM $M$ on input $p$ is the
  projection of $\compute_p$ under the map:
  $$\mfunctype{\stateprojection}{\fullstate}{\nodes} \mid \stateprojection(\beta, p) = p$$
\end{definition}

\begin{definition}{\textbf{Finite-Dimensionally Computable Function}}
  
  A function \functype{\varphi}{X}{R^l}, $X \subset R^n$ is
  \textbf{f.d. computable} over $R$ if there exists a
  finite-dimensional machine, $M$ such that $\varphi$ is the
  input/output map of $M$.
  
\end{definition}

\begin{definition}{\textbf{Decidable, Recognizable, and Co-Recognizable Sets}}
  
  A set $S \subset R^n$ is \textbf{(f.d) decidable} over $R$ if its
  characteristic function \functype{\chi_S}{R^n}{R} is (f.d)
  computable over $R$, where:
  
  $$\chi_S(x) =  \twopartdef{1}{x \in S}{0}{x \notin S}$$
  
  A set $S \subset R^n$ is \textbf{(f.d) recognizable} or
  \textbf{(f.d) semi-decidable} over $R$ if its characteristic
  function \functype{\chi_S}{R^n}{R} is (f.d) computable over $R$,
  where:
  
  $$\chi_S(x) =  \twopartdef{1}{x \in S}{0 \text{\emph{ or undefined}}}{x \notin S}$$
  
  A set $S \subset R^n$ is \textbf{(f.d) co-recognizable} over $R$
  if its co-characteristic function \functype{\chi'_S}{R^n}{R} is (f.d)
  computable over $R$, where:
  
  $$\chi'_S(x) =  \twopartdef{1}{x \notin S}{0 \text{\emph{ or undefined}}}{x \in S}$$
  
\end{definition}

  It should be fairly straightforward to see from the
  definitions that the recognizable sets over $R$ are precisely the
  halting sets over R and the co-recognizable sets are those whose
  complements are recognizable. Less obviously, the decidable sets
  are precisely those that are both recognizable and co-recognizable.

\begin{proposition}{A set $S \subset R^n$ is decidable if and only if it is
  both recognizable and co-recognizable}
\end{proposition}
\begin{proofsketch}
  
  Given semidecision machines, $M$ and $M'$ for both $S$ and $R^n -
  S$, we can contruct a decision machine for $S$ by simulating $M$ and
  $M'$ in parallel, outputting 1 if $M$ halts and 0 if $M'$ halts.  

  \note{The parallelization construction generalizes nicely to any
    integral number of machines. cf \cite{B98} for concrete details}

\end{proofsketch}

\section{Characterization of Decidable Sets}

  We are now in a position to sketch out some results that
  characterize the computable sets over $R$.  Our first such result
  shows that any computable set can be constructed from a finite number
  of well-behaved algebraic objects.

  \begin{definition}{\textbf{Semi-algebraic} and \textbf{Quasi-algebraic Sets}}
    
    A set $S \subset R$ is \textbf{basic semi-algebraic} over an
    ordered ring, $R$, if $S$ is the set of elements in $R$ satisfying
    a finite system of polynomial equalities and inequalities. A set
    is \textbf{semi-algebraic} over $R$ if it is a finite union of basic
    semi-algebraic sets.

    A set $S \subset R$ is \textbf{basic quasi-algebraic} over an
    unordered ring, $R$, if $S$ is the set of elements in $R$ satisfying
    a finite system of polynomial equalities and inequalities. A set
    is \textbf{quasi-algebraic} over $R$ if it is a finite union of basic
    quasi-algebraic sets.
    
  \end{definition}

  We define the initial computation path of length $k$ for a machine
  $M$ on input $p$ as the first $k$ nodes traversed by $M$ while computing
  on $p$.  We define the set of time-T halting paths to be the computations
  performed by $M$ that halt in the first $T$ steps.

  \begin{definition}{\textbf{Initial computation path} and \textbf{time-T halting path set}}

    Let $M$ be a machine over $R$, and let $p$ be an element of
    $\inspace_M$ with $\compute_p = z^0, z^1, \ldots, z^k, \ldots$ \\
    Let $\computepath_p = \beta_0, \beta_1, \ldots, \beta_k, \ldots$.  
    The \textbf{initial computation path} on $\computepath_p$ of
    length $k$ is given by: 
    $$\computepath_p(k) = (\beta_0, \beta_1, \ldots,\beta_k)$$

    The \textbf{time-T path set}, $\haltpaths{T}$, of $M$ is given by:
    $$\haltpaths{T} = \set{\computepath_p(T) \mid T(p) \leq T, p \in \inspace_M}$$

  \end{definition}
  
  \begin{definition}{\textbf{Coincidence set}}

    Let $M$ be a machine over a ring $R$, and let $\computepath = \computepath_{p}(k)$ be
    the initial computation path of length $k$ for some $p \in
    \inspace_M$. The \textbf{coincidence set} of $M$ with respect to $\computepath$, is the
    set of elements in $\inspace_M$ sharing the same initial computation path of length k.
    $\coincidence{\computepath}$, is given by:
    $$\coincidence{\computepath} = 
    \set{p' \in \inspace_M \mid \computepath_{p'}(k) = \computepath}$$
    
    \emph{\note{Coincidence sets are equivalence classes of $\inspace_M$.}}

  \end{definition}

  \begin{theorem}{\textbf{Path Decomposition Theorem}}
    For any machine $M$ over $R$, we have the following:

    \begin{enumerate}
    \item For any $T > 0$, $\halting_T$ is a disjoint union of basic
      semi-algebraic (quasi-algebraic in the unordered case) sets.

    \item $\halting_M$ is a countable union of disjoint basic
      semi-algebraic sets.

    \item For $\computepath \in \haltpaths{T}$,
      $\computefn_M|\coincidence{\computepath}$ is a polynomial map.
    \end{enumerate}
  \end{theorem}

  \begin{proofsketch}
    
    The main idea is that the coincidence sets of a given computation
    path form basic semi(quasi)-algebraic sets.  We can partition
    each time-halting set into finitely many coincidence sets, and
    there are countably many time-halting sets.

    \begin{itemize}
    \item \textbf{(1)} follows from the fact that there are finitely
      many computation paths of length T.  Each computation path
      corresponds to a sequence of branch nodes that corresponds to a
      sequence of polynomial equalities and inequalities, so the
      coincidence set of a computation path is basic
      semi(quasi)-algebraic. Since we can partition $\halting_T$ into
      coincidence sets, each of which corresponds to a basic
      semi(quasi)-algebraic, $\halting_T$ is a union of basic
      semi/quasi-algebraics.
    \item \textbf{(2)} follows from the fact that $\halting_M$ is just
      the union over all $T$ of $\halting_M$, and each $\halting_M$ is
      an equivalence class on $\inspace_M$.
    \item \textbf{(3)} follows from the fact that $\computepath$
      corresponds to exactly one sequence of computation nodes, so
      $\compute_M|\coincidence{\computepath}$ computes the composition of
      $g_{\eta}$ for $\eta \in \computepath$.
    \end{itemize}
  \end{proofsketch}

  \begin{corollary}
    Any computable set is a countable union of disjoin basic
    semi(quasi)-algebraic sets.
  \end{corollary}
\todo{Register Equations}

\input{references.tex}

\end{document}
