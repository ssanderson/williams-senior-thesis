 \chapter{NDET-Machines}
% \label{chap:ndet}

% So far, we have focused our attention on presenting the BSS Machine
% model as it appears in \cite{B98} and \cite{B89}.  Where we have made
% modifications to the theory, our changes have been essentially
% cosmetic, and our original contributions have primarily taken the form
% of new examples and (hopefully) clear explanations of
% some of the more terse sections of the original material.\\

% In this chapter, we present an extension to the BSS Machine model that
% gives rise to an alternative generalization of the complexity class
% $\clnp$.  Our contribution is motivated by the following observations:

% \begin{itemize}

% \item In Definition \ref{def:np}, we characterized the relativized
%   complexity class $\np$ as the class of decision problems efficiently
%   \emph{verifiable} by standard BSS Machines.  This definition
%   generalized the characterization of the classical $\clnp$ as the set
%   of decision problems efficiently verifiable by a standard Turing
%   Machine.\footnote{Recall that for a machine $M$ to be an efficient
%     verifier for some decision problem $S$ is for it to be the case
%     that for each $x \in S$, there exists some additional input value
%     $w$ such that M accepts $(w, x)$ with polynomial cost if and only
%     if $x \in S_{yes}$.  Ignoring the technical details involved in
%     defining acceptance and costs for TMs and BSS Machines, this
%     definition holds equally well for both computational models}
  
% \item In classical theory of computation, there are many ways of
%   characterizing $\clnp$.  An important definition for decision
%   problems equates $\clnp$ with the class of problems that are
%   efficiently \emph{decidable} by a more powerful class of machine
%   called \textbf{nondeterministic Turing Machines}, or
%   NTMs.\footnote{There are other influential characterizations of
%     $\clnp$ in the classical theory.  For example, \cite{AS98} links
%     membership in $\clnp$ to a process of probabilistic verification
%     using a logarithmic number of random bits.  In this thesis,
%     however, we focus primarily on generalizations from efficient
%     computability by nondeterministic Turing Machines.  Considering
%     how other characterizations of $\clnp$ translate to the BSS
%     Machine model could be a promising direction for future work.}

% \item In the classical theory, the standard proof of the equivalence
%   of efficient verifiability and efficient nondeterministic
%   computability depends crucially on the fact that Turing Machines
%   work with a finite alphabet.  To our knowledge no proof exists that
%   does not rely on this fact.
% \end{itemize}

% Since polynomial-time verifiability and nondeterministic
% polynomial-time decidabilty coincide in the classical model, it is
% natural to ask whether the same result holds in the general algebraic
% case.  We attempt to formally answer this question by presenting a
% class of machines, which we call \ndet Machines, that naturally extend
% the BSS Machine model while incorporating important structural
% properties of nondeterministic Turing Machines.  We refer to the class
% of decision problems efficiently (i.e. polynomial-cost) decidable by
% our machines as the class $\ndetp$.  With this terminology in hand,
% the question
% $$\text{efficient verifiability} \stackrel{?}{=} \text{efficient nondeterministic decidability }$$
% can be restated as
% $$\ndetp \stackrel{?}{=} \np .$$
% Adapting proof techniques used to show the classical equivalence of
% efficient verifiability and nondeterministic decidability, we are able
% to show that for any ring $R$,
% $$\p \subseteq \ndetp \subseteq \np.$$
% When our ring $R$ is finite, BSS Machine computation reduces to
% classical Turing Machine computation, which implies that $\ndetp =
% \np$ for finite rings.  On the other hand, (again adapting techniques
% from the classical theory), we are able to show that $\ndetp \subseteq
% \exptime$ for any ring $R$ and any cost function.  This result is not
% true in general for Blum et al.'s $\np$, since $\hn_\integers$ is in
% $\nparg{\integers}$, but is undecidable.  Consequently, over
% $\integers$ with unit cost, we have $\ndetp \subset \np$.\\

% Before we present our \ndet Machines, we once again exhibit the
% classical machine model they generalize.  As in our introduction to
% the standard TM, our reference here is \cite{S06}.

% \section{Classical Nondeterminism}

% \begin{definition}{\textbf{Nondeterministic Turing Machine}}
  
%   A \textbf{nondeterministic Turing Machine} (NTM) is a 7-tuple, $(Q,
%   \Sigma, \Gamma, \delta, q_0, q_{accept}, q_{reject})$, where:
  
%   \begin{itemize}
%   \item $Q$ is a set of machine states.
%   \item $\Sigma$ is an alphabet of input characters, not containing
%     the blank symbol, $\blank$.
%   \item $\Gamma$ is the tape alphabet, where $\blank \in \Gamma$, and
%     $\Sigma \subset \Gamma$.
%   \item \functype{\delta}{Q \times \Gamma}{\power{Q \times \Gamma
%         \times \set{\leftarrow, \rightarrow}}} is the machine's
%     \textbf{nondeterministic transition function}.
%   \item $q_0$ is the initial state of the machine.
%   \item $q_{accept}$ is the machine's accept state.
%   \item $q_{reject}$ is the machine's reject state.
%   \end{itemize}
  
% \end{definition}

% The only change in the definition of an NTM from the definition of a
% standard Turing Machine is in the structure of the transition function
% $\delta$.  The transition function of a standard TM maps to values in
% $Q \times \Gamma \times \set{\leftarrow, \rightarrow}$; the transition
% function of an NTM returns values in $\power{Q \times \Gamma \times
%   \set{\leftarrow, \rightarrow}}$.  Here the symbol $\mathcal{P}(S)$
% denotes the \textbf{power set} of $S$, the set containing all subsets
% of $S$.  We can think of a nondeterministic transition function as
% taking an initial configuration and any (finite) number of next
% configurations instead of a single one.\\

% The computation of a standard Turing Machine is a single sequence of
% configurations, each of which follows from the previous computation.
% By constract, the computation of an NTM is represented as a tree whose
% vertices correspond to different possible configurations for the
% machine.  The root of the tree is the usual initial configuration of a
% TM on input $x$, with symbols of $x$ laid out in the first $n$ cells
% of the machine's tape, the machine's tape head in the leftmost cell,
% and the machine in state $q_0$.  The children of the root node are the
% configurations corresponding to each element of the set output by
% $\delta$, the nondeterministic transition function of $M$.  The tree
% continues in this way, with each level of nodes corresponding to all
% the next configurations of the previous level.  When $\delta$ computes
% a halting configuration (i.e., a configuration whose state is
% $\qaccept$ or $\qreject$), that configuration becomes a leaf of the
% tree.  An NTM halts on an input $x$ if every path through the
% computation tree on $x$ eventually reaches a leaf.  An NTM accepts an
% input $x$ if it halts on $x$ and if at least one of the
% leaves of the computation tree for $x$ is in the state $\qaccept$.\\

% \bigskip
% \begin{minipage}{0.5\linewidth}
%   \begin{center}
%     Standard TM Transition:
%     \functype{\delta}{(Q \times \Gamma)}{(Q \times \Gamma \times
%       \set{\leftarrow, \rightarrow})}\\

%     \vspace{\baselineskip}

%     \detercomptm{}
%   \end{center}
% \end{minipage}
% \begin{minipage}{0.5\linewidth}
%   \begin{center}
%     Nondeterministic TM Transition: \functype{\delta}{(Q \times
%       \Gamma)}{\power{Q \times \Gamma \times \set{\leftarrow,
%           \rightarrow}}}\\
    
%     \vspace{\baselineskip}

%     \scaletopagewidth{\ndetercomptm{}}
%   \end{center}
% \end{minipage}
% \captionof{figure}{Deterministic vs. Nondeterministic Transitions and Computations} \label{fig:det-ndet}
% \bigskip

% \section{Nondeterministic Computation for BSS Machines}

% We have seen that the primary difference in definition between NTMs
% and standard TMs is that the transition function of an NTM computes
% multiple next configurations rather than a single one.  This has the
% effect of transforming the computation of an NTM from a single
% sequence of configurations into a branching tree of ``possible''
% configurations.  We capture this difference with a BSS-style machine
% by leaving computation and shift nodes unchanged and modifying the
% structure of a machine's branch nodes.  For standard BSS Machines,
% each branch node has a unique Yes-Node and a unique No-Node.  We ease
% this restriction for \ndet Machines by allowing each branch node to
% have any nonzero number of Yes and No nodes.  This leads us, as in the
% classical case, to consider computation as a tree of configurations in
% $\nodes \times \statespace_M$ rather than as a single sequence.

% As has been the case throughout our exposition, references to
% polynomial maps can be replaced with rational maps whenever $R$ is a
% field, and branching on $>$ can be replaced with branching on $=$ for
% rings not endowed with a natural order.  Again, the usual caveats
% apply with regard to rational maps and preventing division by zero.\\

% \begin{definition} \textbf{\ndet Machine over R}

%   An \ndet Machine $M$ over a ring R is a finite directed graph with
%   node set $\nodes$.  The collection $\nodes$ contains three
%   distinguished elements: an input node $\nodein$, an accept node
%   $\acept$, and a reject node $\reject$.  The input node has indegree
%   0 and outdegree 1; the accept and reject nodes have outdegree 0.
%   The remaining elements of $\nodes$ are divided into three types:
%   \emph{computation, branch,} and \emph{shift}. The inputs to $M$ are
%   drawn from $R^\infty$.  The state space of $M$ is $R_\infty$. Unlike
%   standard BSS Machines, \ndet machines do not produce output values;
%   they only choose to either accept or reject
%   an input.\\

%   When we wish to emphasize the use of $R^\infty$ as the input space
%   of $M$, we retain the use of the notation $\inspace_M$. The same
%   goes for $R_\infty$ and $\statespace_M$.

%   As with FDM's and full BSS Machines, each node has an associated map
%   and a set of next nodes:

%   \begin{enumerate}
%   \item Associated with the input node $\nodein$ is the input map
%     \functype{I_\infty}{R^\infty}{R_\infty} given in Definition
%     \ref{def:io-map}. We denote the unique next node of $\eta_1$ by
%     $\beta_{\eta_1}$ or just $\beta_1$.

%   \item The accept and reject nodes have no associated map. The accept
%     and reject nodes have no next node.

%   \item Associated with each computation node $\eta$ is a polynomial
%     map \functype{\widehat{g}_\eta}{R_\infty}{R_\infty}. We denote the
%     unique next node of $\eta$ by $\beta_\eta$.
    
%   \item Associated with each branch node $\eta$ is a nonzero
%     polynomial map \functype{\widehat{h}_\eta}{R_\infty}{R}, a
%     nonempty set of Yes-Nodes, $\beta^+_\eta = \set{\yesnode{1},
%       \yesnode{2}, \ldots, \yesnode{i}}$, and a nonempty set of
%     No-Nodes, $\beta_\eta^- = \set{\nonode{1}, \nonode{2}, \ldots,
%       \nonode{j}}$.  We associate the Yes-Nodes with the condition
%     $h(x) \geq 0$, and the No-Nodes with the condition $h(x) < 0$. We
%     refer to the max of $i$ and $j$ as the \textbf{branching degree}
%     of $\eta$, and we refer to the maximum branching degree of any
%     node in $M$ as the branching degree of $M$.

%   \item Associated with each shift node $\eta$ is a next node
%     $\beta_\eta$ and a shift map
%     \functype{\sigma_\eta}{R_\infty}{R_\infty}, which is either
%     $\sigma_l$ or $\sigma_r$. The maps $\sigma_l$ and $\sigma_r$, are
%     the same as those used in the definition of a standard BSS
%     Machine.

%   \end{enumerate}
% \end{definition}

% The definition of \emph{configuration} given in Definition
% \ref{def:configuration} remains unchanged for \ndet Machines, as do
% the definitions of \emph{accepting, rejecting, terminal}, and
% \emph{non-terminal configuration}. The notions of next configuration
% and computation, however, require some modification in our new
% setting.

% \begin{definition}{\textbf{Next Configuration Set}}

%   Let $M$ be an \ndet Machine over $R$, and let $z = (\eta, x) \in
%   \nodes_M \times \statespace_M$ be a configuration of $M$.  We define
%   the \textbf{next configuration set} of $z$, denoted $H(z)$, as
%   follows:

%   \begin{enumerate}
%   \item If $\eta = \eta_1$, $H(z) = \set{(\beta_1, x)}$.
%   \item If $\eta \in \set{\accept, \reject}$, $H(z) = \emptyset$.
%   \item If $\eta$ is a computation node, $H(z) = \set{(\beta_\eta, g_\eta(x))}$.
%   \item If $\eta$ is a shift node, $H(z) = \set{(\beta_\eta,
%       \sigma_\eta(x))$}.
%   \item If $\eta$ is a branch node:\footnote{As with BSS Machines, when
%       $R$ is to be considered without order we replace the conditions
%       $h(x) \geq 0$ and $h(x) < 0$ with $h(x) = 0$ and $h(x) \neq 0$.}
%     $\twopartdef  
%     {H(x) = \set{(\beta, x) \mid \beta \in \beta_\eta^+}} {h(x) \geq 0}
%     {H(x) = \set{(\beta, x) \mid \beta \in \beta_\eta^-}} {h(x) < 0.} 
%     $
%   \end{enumerate}

%   In keeping with the notation used in Chapter \ref{chap:background},
%   we abbreviate the expression ``$z'$ is in the next node set of $z$''
%   by writing $z \yields z'$.  Note that for an \ndet Machine
%   configuration $z$, there may be multiple configurations $z'$ such
%   that $z \yields z'$.
% \end{definition}

% \vspace{\baselineskip}

% For any configuration $z = (\eta, x)$ for which $\eta$ is not a branch
% node, $H(z)$ is just the set containing the unique next configuration
% of $z$ as determined by the same rules defining next configurations
% for standard BSS Machines. In the case that $\eta$ is a branch node,
% there are two possibilities for $H(z)$.  If the branching function
% $h_\eta(x)$ computes a value greater than or equal to $0$, then $H(z)$
% is the set of all pairs $(\beta, x)$, such that $x$ is unchanged, and
% $\beta$ is a Yes-Node of $\eta$.  If $h_\eta(x) < 0$, then $H(z)$ is
% the set of all pairs $(\beta, x)$ such that $x$ is unchanged, and
% $\beta$ is a No-Node of $\eta$.

% \begin{definition}{\textbf{\ndet Machine Computation}}
  
%   Let $M$ be an \ndet Machine over $R$, and let $x \in \inspace_M$.
%   The computation performed by $M$ on input $x$, $\compute_M(x)$ is a
%   (possibly infinite) directed tree whose vertices are elements of
%   $\nodes_M \times \statespace_M$.\footnote{We use the term ``vertex''
%     rather than node here to avoid confusion with the nodes of the
%     machine $M$ itself.} The structure of $\compute_M(x)$ is defined
%   recursively as follows:
  
%   \begin{itemize}
%   \item The root of $\compute_M(x)$ is the initial configuration of
%     $M$ on input $x$ given by $(\eta_1, I_\infty(x))$.
%   \item If $z$ is any vertex of $\compute_M$, and $z'$ is a
%     configuration of $M$ such that $z \yields z'$, then $z'$ is a
%     child vertex of $z$.\footnote{It immediately follows that a
%       configuration appearing in $\compute_M(x)$ is a leaf if and only
%       if it is a terminal configuration of $M$.}
%   \end{itemize}
  
% \end{definition}

% \note{The vertices of a nondeterministic computation $\compute_M(x)$
%   can be organized into levels according their distance from the
%   root. Level 1 contains only the root vertex, $(\eta_1,
%   I_\infty(x))$.  Level 2 contains all of the next configurations of
%   $z_1$.  Level 3 contains all of the next configurations of nodes in
%   Level 2, and so on. A given configuration can appear multiple times
%   in the tree and can even appear multiple times in a particular level
%   if different nondeterministic paths of the same length result in the
%   same configuration.}

% \begin{definition}{\textbf{Halting Computation Branch}}
  
%   Let $M$ be an \ndet Machine over $R$, and let $\compute_M(x)$ be the
%   computation of $M$ on an input $x$.  Suppose now that
%   $\compute_M(x)$ contains at least one leaf vertex, and let $z$ be
%   such a vertex.  We define the \textbf{halting computation branch}
%   $\subcompute_M(x, z)$ to be the unique directed path in
%   $\compute_M(x)$ from the root of $\compute_M(x)$ to $z$.  We denote
%   the set of all halting computation branches in $\compute_M(x)$ by
%   $\branches_M(x)$.
% \end{definition}

% \note{Each halting computation branch of a machine $M$ is a finite
%   sequence of configurations $(z_1, z_2, \ldots, z_k)$ such that $z_1$
%   is the initial configuration of $M$ for some input $x$, $z_k$ is a
%   terminal configuration, and for all $i < k$, we have $z_i \yields
%   z_{i+1}$.  Thus elements of $\branches_M$ have exactly the same
%   structure as the computations of standard BSS Machines, which means
%   that all the attributes and functions defined for BSS Machine
%   computations can be applied to \ndet Machine computation branches.
%   In particular, the cost of a computation branch can defined in
%   exactly the manner we used to define cost for BSS Machine
%   computations in Definition \ref{def:cost}.}

% \begin{definition} \textbf{NDET-Machine Halting, Acceptance and Rejection}

%   An \ndet Machine $M$ is said to \textbf{halt} on input $x$ if it
%   contains finitely many vertices.  Equivalently, an \ndet Machine
%   halts on $x$ if every directed path through $\compute_M(x)$
%   eventually reaches a terminal configuration.  We use the symbol
%   $\halting_M$ to denote the \textbf{Halting Set} of $M$, which is the
%   subset of $\inspace_M$ on which $M$ halts.
  
%   An \ndet Machine $M$ is said to \textbf{accept} an input $x$ if $M$
%   halts on $x$ and at least one leaf of $\compute_M(x)$ is an
%   accepting configuration of $M$.

%   If $M$ halts on $x$ and no leaf in $\compute_M(x)$ is an accepting
%   configuration, we say that $M$ \textbf{rejects} $x$.
  
% \end{definition}

% \section{Computation Cost for  NDET Machines}

% \begin{definition}{\textbf{Nondeterministic Computation Cost}}

%   Let $M$ be an \ndet Machine over a ring $R$ with associated height
%   function \functype{ht_R}{R}{\reals}.  Let $x \in \inspace_M$ be an
%   input such that $M$ halts on $x$, and let $\Psi$ be the set of all
%   halting computation branches in $\compute_M(x)$.

%   The \textbf{cost} of $\compute_M(x)$ is given by $\max\limits_{\psi
%     \in \Psi}(\cost_M(\psi))$, where $\cost_M(\psi)$ is defined as in
%   Definition \ref{def:cost}.

% \end{definition}

% \begin{definition}{$\ndettime_{f(x)}$}

%   A decision problem $S \subseteq R^\infty$ is said to belong to
%   $\ndettime_{f(x)}$ if there exists an NDET machine that decides $S$
%   with computation cost bounded by $f(\size(x))$ for all $x$ in
%   $S_{yes}$.
  
% \end{definition}

% \begin{definition} $\ndetp$
  
%   A language, $S$ is in $\ndetp$ if there exists a machine $M$ and
%   real constants constant $c$ and $q$ such that, $\forall x \in S$,
%   $M$ accepts $x$ with cost $c \times \size(x)^q)$.
  
% \end{definition}

\section{$\ndetp$ and Deterministic Complexity}

In this section we present some results relating the class $\ndetp$ to
the deterministic time complexity classes described in Chapter 2.
Most of the proofs presented here are straightforward generalizations
of results from classical complexity theory.\\

Our first result is analogous to the classical result that every
nondeterministic time complexity class contains its deterministic
equivalent.  As in the Turing Machine case, this is unsurprising,
since adding the power of nondeterminism can only make computation of
a problem more efficient.  Our proof essentially consists in simply
noting that every deterministic machine is also a valid
nondeterministic machine that happens not to take advantage of the
additional power afforded by nondeterminism.

\proposition{Let $R$ be a ring with any height function, and let $(S,
  S_{yes})$ be a decision problem over $R$. If $M$ is a BSS machine
  that decides $S$ in time $f(\size(x))$, then $M$ also decides $S$ in
  time $f(\size(x))$ when interpreted as an NDET machine.\\}

\proof{ As noted above, the only difference between the definitions of
  \ndet machines and standard BSS machines is that every branch node
  $\eta$ of BSS machine has a single $\beta_\eta^+$ and a single
  $\beta_{\eta}^-$, whereas each branch node of an NDET machine may
  have multiple Yes and No nodes. Thus we can regard standard BSS
  machines as a special case of NDET machines for which every node has
  branching degree 1, and it makes sense to talk about
  ``interpreting'' a BSS Machine $M$ as an NDET machine.\footnote{We
    are abusing notation slightly here by equating the next nodes of a
    BSS Machine with those of an \ndet Machine.  Formally, BSS Machine
    branch nodes have a single Yes Node and a single No Node, whereas
    \ndet Machines have sets of Yes and No Nodes.  Thus technically we
    should say that we can transform a BSS Machine $M$ into an \ndet
    Machine $M'$ that accepts and rejects exactly the same values as
    $M$ by replacing each branch node $\eta$ in $M$ with a branch node
    $\eta'$ in $M'$ whose Yes Node set contains the single element
    $\beta_\eta^+$, and whose No Node set contains the single element
    $\beta_\eta^-$.}\\

  Let $x$ be an element of $S$, and let $M$ be a BSS machine that
  decides $S$, now interpreted as an NDET machine. Since $M$ has
  maximum branching degree 1, every configuration of $M$ has at most 1
  one valid next configuration, which implies that there is at most
  one halting computation branch $\subcompute$ in the computation of
  $M$ on $x$.  If such a $\subcompute$ exists, it contains exactly the
  same sequence of configurations as the computation, $\compute_M(x)$
  performed by $M$ on $x$ when interpreted as a standard BSS
  Machine. In particular, the terminal configuration of $\subcompute$
  is accepting if and only if $\compute_M(x)$ is an accepting
  computation. It follows that $M$ accepts $x$ when interpreted as an
  \ndet Machine if and only if it also does so when interpreted as a
  BSS Machine.

\corollary{Over any ring $R$ with any height function, we
  have: 
  $$\dtime \subseteq \ndettime.$$ 
  In particular, we have: 
  $$\p \subseteq \ndetp.$$}

Our next result generalizes the classical proof that any
nondeterministic Turing Machine can be simulated by a deterministic
Turing Machine with at most an exponential slowdown in runtime. 

\theorem{Let $R$ be a ring with any height function, and let $(S,
  S_{yes})$ be a decision problem over $R$.  If $M$ is an NDET Machine
  that decides $S$ with cost bounded by $f(\size(x))$ for all $x$ in
  $S$, then there exists a standard BSS machine, $M'$ that decides $S$
  in time $O(D^{f(\size(x))})$, where $D$ is the maximum branching degree of
  any node in $M$.}

\vspace{\baselineskip}

\proof{ Algorithm \ref{alg:Simulate-NDET} uses the existence of the
  NDET machine $M$ to decide $S$ with necessary given bound.  The
  essential idea is that on input $x$ we can breadth-first search
  through the configuration space of $M$, checking all possible paths
  of length less than $f(\size(x))$. 

  \begin{algorithm} 
    \caption{Simulate-NDET} \label{alg:Simulate-NDET}
    \begin{algorithmic}
      \Require $x \in R^\infty$
      \Ensure $\mathtt{queue} = \set{(\eta_1, x)}$, $\mathtt{maxLength} = f(\size(x))$
      \While{!\texttt{queue.empty}}
      \State $z = \mathtt{queue.next()}$
      \If{$\mathtt{length}(z) > \mathtt{maxLength}$} 
      \State \textbf{reject}
      \EndIf
      \State Compute next configuration set $H_M(z)$
      \For{configuration $(x, \eta)$ in $H_M(z)$} 
      \If{$\eta$ = $\eta_{accept}$}
      \State \textbf{accept}
      \Else{ \texttt{Insert} $(x, \eta)$ into $\mathtt{queue}$}
      \EndIf
      \EndFor
      \EndWhile
      \State \textbf{reject}
    \end{algorithmic}
  \end{algorithm}}  

Our algorithm proceeeds by processing configurations in
$\compute_M(x)$ in breadth-first search order. If at any point during
the algorithm we encounter an accepting configuration, we know that
$M$ accepts $x$, so we also accept and terminate the simulation.  If
we process every configuration in $\compute_M(x)$ without encountering
an accepting configuration, it must be the case that every computation
branch in $\branches_M(x)$ is rejecting, so we reject.  Thus our
algorithm accepts $x$ if and only if $M$ also accepts $x$, so it is a
decision procedure for $S$. Note that our simulation is guaranteed to
halt on inputs from $S$ by the fact that our original machine $M$ is a
decider for $S$, which entails that every computation branch in
$\branches_M(x)$ eventually halts.

In our pseudo code, the variable \texttt{queue} denotes
a queue of encoded machine configurations that provides \texttt{next}
and \texttt{insert} operations for retrieving and storing
configuration encodings. If $K$ is the maximum dimension of any
computation node in $M$, then we can store encoded configurations of
$M$ using $O(f(\size(x) + K))$ space per configuration, since this is
the highest possible index of $\statespace_M$ that can be modified by
$M$ in time $f(\size(x))$.  Since the configuration queue is the only
part of our algorithm requiring dynamic storage, we can implement our
queue so that the next configuration to be retrieved is always closest
to the first $K$ coordinates of $M$.  Moreover, since we never re-use
a configuration that has already been processed, we can implement
\texttt{next} by simply performing $f(\size(x))$ shift operations,
perhaps alternating with computation steps to ensure that we retain
any necessary bookkeeping state.  If we implement the queue structure
as a delimited sequence of stored configurations, we can implement
\texttt{insert} using $O(f(\size(x)) \times \mathtt{queue.length}))$
operations by alternating between shift and computation nodes to the
new configuration to the end of the queue while leaving the rest of
the statespace unchanged.\\

Since $\compute_M(x)$ has cost bounded by $\size(x)$, every
computation branch in $\compute_M(x)$ has length bounded by
$\size(x)$. Since $M$ has maximum branching degree $D$, it follows
that there are at most $O(D^{f(\size(x))})$ configurations in
$\compute_M(x)$, so there are also at most $O(D^{f(\size(x))})$
configurations in \texttt{queue} at any point during our algorithm.
Thus an upper bound on the cost of inserting a new configuration is
$$O(f(\size(x)) \times D^{f(\size(x))}),$$ 
and an upper bound on the cost to process each configuration is
$$O(f(\size(x)) + f(\size(x)) \times D^{f(\size(x)))} = O(D^{f(\size(x))}).$$
Since again there are at most $O(D^{f(\size(x))}$ configurations
processed by our algorithm, our overall runtime is bounded by
$$O(D^{f(\size(x))}) \times O(D^{f(\size(x))}) = O(D^{f(\size(x))}).$$

An immediate corollary of our simulation algorithm is the following:

\corollary{Every problem decidable by an \ndet Machine is decidable by a
  BSS Machine.}

\vspace{\baselineskip}

We can make this result stronger in the case that our \ndet Machine
runs with polynomial cost.

\begin{definition}{\textbf{$\exptime$}}
  
  A decision problem $S$ is in class $\exptime$ if there exists a BSS
  Machine $M$, a polynomial $p$, and a constant $n \in \naturals$ such
  that $M$ decides $S$ with cost bounded by $$2^{p(\size(x))^n}$$
\end{definition}

Plugging in any polynomial function for the $f$ in our algorithm
above, we can reduce our runtime bound to the form required for
membership in $\exptime$.  Thus we have the following:

\corollary{$\ndetp \subseteq \exptime$}

\vspace{\baselineskip}

The above results show that nondeterminism does not grant us any more
power as far as computability goes; it ``merely'' gains us at most an
exponential decrease in runtime for decision procedures.  Again, this
is in agreement with the classical notion of nondeterminism.\\

\section{$\ndetp$ and $\np$}

We now wish to consider the relationship between the $\ndetp$ and
$\np$ as it has been developed by Blum et al and others.  Since these
classes generalize notions that are equivalent in the classical model,
the natural question to ask is whether the same equivalence holds in
general.  We first show that any problem in $\ndetp$ is also in $\np$.
The simplest way of showing this result is to examine the relationship
between $\ndetp$ and a restricted version of $\np$ which allows only
binary witnesses.

\begin{definition}{\textbf{$\dnp$}}
  
  A decision problem $S \subseteq R^\infty$ over a ring $R$ is in the
  class $\dnp$ if there exist positive integers $c$ and $q$ and a BSS
  Machine $M$ over R with $\inspace_M = \integers_2^\infty \times
  R^\infty$ such that:

  \begin{enumerate}
  \item If $x \in S_{yes}$ then there exists a $w \in \integers_2^\infty$, such that
    $M$ accepts $(w, x)$ and $cost_M(w,x) \leq c(size(x))^q$.
  \item If $x \in S_{no}$, then there is no such $w$ such that $M$
    accepts $(w, x)$.
  \end{enumerate}

\end{definition}

\begin{example}

  A natural example of a problem in $\dnp$ is \subsum.  To show this,
  we must exhibit a machine $M$ running with polynomial cost which
  takes as input a binary sequence $w$ and a \subsum instance $x =
  \langle (\set{x_1, x_2, \ldots x_k}, t) \rangle$.  Our machine $M$
  must have the property that accepts $(w,x)$ for some $w$ if and only
  if $\set{x_1, x_2, \ldots, x_k}$ has a subset whose sum is $t$.
  Such a machine is easily constructed by noting that the sought-after
  subset exists if and only if there exists an n-tuple $(w_1, w_2,
  \ldots w_k) \in \integers_2^k$ such that $\sum\limits_{i=1}^k w_ix_i
  = t$.  Thus we can construct the necessary machine $M$ by simply
  taking the dot product of $w$ with the subset encoded by $x$,
  accepting if the result of this operation is $t$ and rejecting
  otherwise.
  
\end{example}

We can adapt techniques used to prove the classical equivalence of
poly-time verifiability and nondeterministic poly-time decidability to
show the following result.

\theorem{$\dnp = \ndetp$}

\begin{proof}

  Let $S \in \dnp$.  Then by definition, there exists a BSS Machine
  $M$ with $\inspace_M = \integers_2^\infty \times R^\infty$ and
  integers $c$ and $q$ such that, for any $x$ in $S$, $M$ accepts some
  pair $(w,x)$ with cost bounded by $c \times \size(x)^p$ if and only
  if $x \in S_{yes}$.  We can use $M$ construct an \ndet machine
  deciding $S$ with polynomial cost using the following algorithm:

  \begin{algorithm}
    \caption{$\dnp \rightarrow \ndetp$} \label{alg:dnp->ndet}
    \begin{algorithmic}
      \Require $x \in R^\infty$ 
      \State Nondeterministically set $w$
      equal to all binary strings with length $\leq$ $c \times
      \size(x)^p$.
      \State Simulate $M$ on $(w,x)$, accepting if $M$ accepts and rejecting if $M$ rejects.
    \end{algorithmic}
  \end{algorithm}
\end{proof}

Note that it is sufficient to check only binary strings of size
bounded by $c \times \size(x)^p$ because the cost of computing even a
single step for larger witnesses would exceed the cost bound on
accepting computations for $M$.  


Blum et al. show in \cite{B89} that $\parg{\Z{2}}$ with
respect to unit cost and $\parg{\integers}$ with respect to bit cost
are equivalent to the classical $\p$, with similar results obtaining
for the analogous $\np$ classes.  Thus we expect that $\ndetp$ and
$\np$ should coincide in these cases.  We prove the slightly more
general result that $\ndetp = \np$ for any ring $R$ with height
function $ht_R$ such that, for any $k \in R$ there are at most
finitely many elements of $R$ Our proof follows the classical case by
showing that $\ndetp$ machines can match the computational power of
$\np$ machines by simply generating all possible witnesses.  This
argument depends crucially on the fact that for a finite ring there
can be at most exponentially many witnesses of a given length.  Since
this is no longer the case for infinite rings, it becomes less clear
under what conditions the equality still holds.

\theorem{Let $R$ is a ring with height function $ht_R$ such that, for
  any $N \in reals$, there are only finitely many elements of $R$ with
  size less than or equal to $N$.  With respect to $ht_R$, $\ndetp =
  \np$.

\theorem{When considered with unit cost, $\nparg{\integers}
  \not\subset \decarg{\integers}$}
\proof{ It is easy to formulate Hilbert's Tenth Problem, which asks if
  an arbitrary diophantine equation has solutions over the integers,
  as a decision problem over $\integers$ It is also easy to show that
  this problem is in $\np$, since a witness for a solvable diophantine
  equation is the solution in queston. Since it is well known that
  Hilbert's Tenth Problem is undecidable we have our desired result.
  For more details see \cite{B98}, Chapter 6.}

The above result shows that the classical equivalence of efficient
verifiability and nondeterministic computability is not necessarily
valid for rings other than $\integers_2$.  Two natural questions
arise concerning the relationship between $\ndetp$ and $\np$.  

\begin{itemize}
\item Is it always the case that $\ndetp \subseteq \np$.
\item Under what circumstances is it the case that $\ndetp = \np$?
\end{itemize}

We give an affirmative answer to the first question.  This is
because, given an NDET Machine $M$ that decides a set $S$, we can
produce an NP Machine $M'$ that also decides $S$ by labelling each
node in $M$ by a unique value (or series of values if necessary)
from $R$ and replacing each branch node of $M$ with a subroutine
that reads the next unread value in the witness $w$, and transitions
to the node labelled by that integer if it is a valid next node for
the current configuration. For such a machine, an accepting witness
is one that encodes the sequence of nondeterministic choices made by
$M$ on some accepting path.

\theorem{Let $S$ be a decision problem over a ring $R$ with height
  function $ht_R$, and let $M$ be an NDET machine that decides $M$
  with cost bounded by $O((\size(x)))$.  Then there exists an NP
  machine, $M'$ which also decides $S$ in time $O(f(\size(x)))$}

\todo{I think this might work better written out in algorithm style
  like the one above.  Also, should the statement about assuming
  branching degree 2 be broken out into a Lemma?}

\proof{Let $S$ and $M$ be as stated above.  We assume without loss of
  generality that $M$ has maximum branching degree 2, since we can
  always replace a branch node of higher branching degree with a chain
  of branch nodes of degree 2, and doing so increases the runtime of
  $M$ by at most a multiplicative constant factor of $d$.  We
  construct the NP machine $M'$ by starting with $M$ and replacing
  each branch node $\eta$ of $M$ with a subroutine that first computes
  the branching check associated with $\eta$, then queries the witness
  string $w$ and decides which of the possible next nodes to
  transition into based on the value stored in the first coordinate of
  $w$.}

Toward answering the second question, we show that a sufficient
condition for $\ndetp = \np$ is that all values in $R^\infty$ of
size $s$ or less be enumerable by an NDET machine in
nondeterministic time $O(log s)$.  We conjecture that this condition
is also sufficient.  

\theorem{Let $R$ be a ring with associated height function
  satisfying the property that there exists an NDET Machine that
  enumerates every value in $R^\infty$ with size at most $s$ in
  nondeterministic time $O(\log s)$.

  \proof{
    Let $S \in \np$.  Then there exists a machine $M$ such that for
    every $x$ in $S$ there exists a $w$ such that $\computefn_M(x, w)
    = 1$ and $cost_M(x, w) \leq p(size(x))$, where p is some
    polynomial function.  It immediately follows that $w$ must have
    size less than $p(size(x))$, or else computing a single step with
    $w$ in a register of $\statespace_M$ would render the cost of
    computing a single step to be greater than the given bound on the
    runtime of $M$.  Thus we can construct an NDET-Machine which, on
    input $x$, nondeterministically generates all possible witnesses
    of length at most $p(size(x))$, and then for each possible witness
    $w$ simulates $M$ on input $w$.
  }

\todo{Section on digital nondeterminism equivalence and DNP-Complete problems.}


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "main"
%%% End: 
