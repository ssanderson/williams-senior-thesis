\chapter{NDET-Machines}
\label{chap:ndet}

Up until now, we have focused our attention on presenting the BSS
Machine model as it appears in \cite{B89} and \cite{B98}.  Where we
have made modifications to the theory, they have been essentially
cosmetic, and our original contributions have mostly consisted of new
examples and (hopefully) clear explanations of some of the more terse
sections of our source material.\\

In this chapter, we present an original extension to the BSS Machine
model that results in an alternative generalization of the complexity
class $\clnp$.  Our contribution is motivated by the following
observations:

\begin{itemize}

\item In Definition \ref{def:np}, we characterized the relativized
  complexity class $\np$ as the class of decision problems efficiently
  verifiable by a standard BSS Machine.  This definition naturally
  generalized the chracterization of the classical $\clnp$ as the set
  of decision problems efficiently verifiable by a standard Turing
  Machine.\footnote{Recall that for a machine $M$ to be an efficient
    verifier for some decision problem $S$ is for it to be the case
    that for each $x \in S$, there exists some additional input value
    $w$ such that M accepts $(w, x)$ with polynomial cost if and only
    if $x \in S_{yes}$.  Ignoring the technical details involved in
    defining costs for TMs and BSS Machines, this definition holds
    equally well for both computational models}
  
\item In classical theory of computation, there are several
  characterizations of $\clnp$ that turn out to be equivalent to the
  verifiability definition.  In particular, the class of problems
  efficiently verifiable by standard Turing Machines turns out to be
  equivalent to the class of problems that are efficiently
  \emph{computable} by a more powerful class of machine called
  nondeterministic Turing Machines.\footnote{There are other
    influential characterizations of $\clnp$ in the classical theory.
    For example, \cite{AS98} links membership in $\clnp$ to a process
    of probabilistic verification using a logarithmic number of random
    bits.  In this thesis, however, we focus primarily on
    generalizations from efficient computability by nondeterministic
    Turing Machines.  Considering how other characterizations of
    $\clnp$ translate to the BSS Machine model could be a promising
    direction for future work.}

\item In the classical theory, the standard proof of the equivalence
  of efficient verifiability and efficient nondeterministic
  computability depends crucially on the fact that Turing Machines
  work with a finite alphabet.  To our knowledge no proof exists that
  does not rely on this fact.
\end{itemize}

In light of the above observations, we are led to consider how the
nondeterministic Turing Machine could be generalized to computation
over an arbitrary ring/field.  We present a class of machines, which
we call \ndet Machines, that naturally extend the BSS
Machine model while also preserving important structural properties of
nondeterministic Turing Machines.  We refer to the class of problems
that are efficiently (i.e. polynomial-cost) computable by our machines
as $\ndetp$.\\

We are also naturally led to consider whether the problems efficiently
computable by our new machines coincide with the class $\np$ as
defined by Blum et al.  Very generally, we are able to show that
$$\p \subseteq \ndetp \subseteq \np$$
with $\ndetp = \np$ for finite rings, and $\ndetp \subset \np$ for $R
= \integers$ with unit cost.  We are also able to show that every
language in $\ndetp$ is decidable by some deterministic BSS Machine,
which is not always true of Blum et al.'s $\np$.\\

Before we present our \ndet Machines, we once again exhibit the
classical machine model they generalize.  As in our introduction to
the standard TM, our reference here is \cite{S06}.

\section{Classical Nondeterminism}

\begin{definition}{\textbf{Nondeterministic Turing Machine}}
  
  A \textbf{nondeterministic Turing Machine} (NTM) is a 7-tuple, $(Q,
  \Sigma, \Gamma, \delta, q_0, q_{accept}, q_{reject})$, where:
  
  \begin{itemize}
  \item $Q$ is a set of machine states.
  \item $\Sigma$ is an alphabet of input characters, not containing
    the blank symbol, $\blank$.
  \item $\Gamma$ is the tape alphabet, where $\blank \in \Gamma$, and
    $\Sigma \subset \Gamma$.
  \item \functype{\delta}{Q \times \Gamma}{\power{Q \times \Gamma
        \times \set{\leftarrow, \rightarrow}}} is the machine's
    \textbf{nondeterministic transition function}.
  \item $q_0$ is the initial state of the machine.
  \item $q_{accept}$ is the machine's accept state.
  \item $q_{reject}$ is the machine's reject state.
  \end{itemize}
  
\end{definition}

The only change in the definition of an NTM from the definition of a
standard Turing Machine is in the output of the transition function
$\delta$.  The transition function of a standard TM returns values in
$Q \times \Gamma \times \set{\leftarrow, \rightarrow}$; the transition
function of an NTM returns values in $\power{Q \times \Gamma \times
  \set{\leftarrow, \rightarrow}}$.  Here the symbol $\mathcal{P}(S)$
denotes the \textbf{power set} of $S$, the set containing all subsets
of $S$.  Thus we can think of a nondeterministic transition function
as taking an initial configuration and any number of next
configurations instead of a single one.\\

The computation of an NTM $M$ for an input $x$ can be thought of as a
tree whose nodes correspond to different possible configurations for
the machine.  The root of the tree is the usual initial configuration
of a TM on input $x$, with symbols of $x$ laid out in the first $n$
cells of the machine's tape, the machine's tape head in the leftmost
cell, and the machine in state $q_0$.  The children of the root node
are the configurations corresponding to each element of the set output
by $\delta$, the nondeterministic transition function of $M$.  The
tree continues on in this way, with each level of nodes corresponding
to the possible next configurations of the previous level.  When
$\delta$ computes a halting configuration (i.e., a configuration whose
state is $\qaccept$ or $\qreject$), that configuration becomes a leaf
of the tree.  An NTM is said to halt on an input $x$ if every path
through the computation tree on $x$ eventually reaches a leaf.  An NTM
accepts an input $x$ if it halts on $x$ and if at least one of the
leaves of the computation tree for $x$ is in the state $\qaccept$.\\

\todo{Example computation tree.}

\section{Nondeterministic Computation}

We have seen that the primary difference in definition between NTMs
and standard TMs is that the transition function of an NTM computes
multiple next configurations rather than a single one, and we have
seen that this transforms the computation of an NTM from a sequence of
configurations to a branching tree of possible configurations.  We
capture this change with a BSS-style machine by leaving computation
and shift nodes unchanged and modifying the structure of a machine's
branch nodes.  For standard BSS Machines, each branch node has a
unique Yes-Node and a unique No-Node.  For our \ndet Machines, we
allow each branch node \emph{any} number of Yes and No nodes.  This
leads us, as in the classical case, to consider computation as a tree
of configurations in $\nodes \times \statespace_M$ rather than as a
fixed sequence of such configurations.\\

As has been the case throughout our exposition, references to
polynomial maps can be replaced with rational maps whenever $R$ is a
field, and branching on $>$ can be replaced with branching on $=$ for
rings not endowed with a natural order.

\begin{definition} \textbf{\ndet Machine over R}

  An \ndet Machine $M$ over a ring R is a finite directed graph with
  node set $\nodes$.  The collection $\nodes$ contains three
  distinguished elements: an input node $\nodein$, an accept node
  $\accept$, and a reject node $\reject$.  The input node has indegree
  0 and outdegree 1; the accept and reject nodes have outdegree 0.
  The remaining elements of $\nodes$ are divided into three types:
  \emph{computation, branch,} and \emph{shift}.\\

  The inputs to $M$ are drawn from $R^\infty$.  The state space of $M$
  is $R_\infty$. Unlike standard BSS Machines, \ndet machines do not
  produce output values; they only choose to either accept or reject
  an input.\\

  When we wish to emphasize the use of $R^\infty$ as the input space
  of $M$, we retain the use of the notation $\inspace_M$. The same
  goes for $R_\infty$ and $\statespace_M$.

  As with FDM's and full BSS Machines, each node has an associated map
  and a set of next nodes:

  \begin{enumerate}
  \item Associated with the input node $\eta_1$ is the input map
    \functype{I_\infty}{R^\infty}{R_\infty} given by Definition
    \ref{def:io-map}. We denote the unique next node of $\eta_1$ by
    $\beta_{\eta_1}$ or just $\beta_1$.

  \item Associated with both the accept and reject nodes is the
    output map \functype{O_\infty}{R_\infty}{R^\infty} given in
    Definition \ref{def:io-map}.  The accept and reject nodes have
    no next node.

  \item Associated with each computation node $\eta$ is a polynomial
    map \functype{\widehat{g}_\eta}{R_\infty}{R_\infty}. We denote the
    unique next node of $\eta$ by $\beta_\eta$.
    
  \item Associated with each branch node $\eta$ is a nonzero
    polynomial map \functype{\widehat{h}_\eta}{R_\infty}{R}, a
    nonempty set of Yes-Nodes, $\beta^+_\eta = \set{\yesnode{1},
      \yesnode{2}, \ldots, \yesnode{i}}$, and a nonempty set of
    No-Nodes, $\beta_\eta^- = \set{\nonode{1}, \nonode{2}, \ldots,
      \nonode{j}}$.  We associate the Yes-Nodes with the condition
    $h(x) \geq 0$, and the No-Nodes with the condition $h(x) < 0$. We
    refer to the max of $i$ and $j$ as the \textbf{branching degree}
    of $\eta$, and we refer to the maximum branching degree of any
    node in $M$ as the branching degree of $M$.

  \item Associated with each shift node $\eta$ is a next node
    $\beta_\eta$ and a shift map
    \functype{\sigma_\eta}{R_\infty}{R_\infty}, which is either
    $\sigma_l$ or $\sigma_r$. The maps $\sigma_l$ and $\sigma_r$, are
    the same as those used in the definition of a standard BSS
    Machine.

  \end{enumerate}
\end{definition}

The definition of \emph{configuration} given in Definition
\ref{def:configuration} remains unchanged for \ndet Machines, as do
the definitions of \emph{accepting, rejecting, terminal}, and
\emph{non-terminal configuration}. The notions of next configuration
and computation, however, require some modification for this new
setting.

\begin{definition}{\textbf{Next Configuration Set}}

  Let $M$ be an \ndet Machine over $R$, and let $z = (\eta, x) \in
  \nodes_M \times \statespace_M$ be a configuration of $M$.  We define
  the \textbf{next configuration set} of $z$, denoted $H(z)$, as
  follows:

  \begin{enumerate}
  \item If $\eta = \eta_1$, $H(z) = \set{(\beta_1, x)}$.
  \item If $\eta \in \set{\accept, \reject}$, $H(z) = \emptyset$.
  \item If $\eta$ is a computation node, $H(z) = \set{(\beta_\eta, g_\eta(x))}$.
  \item If $\eta$ is a shift node, $H(z) = \set{(\beta_\eta,
      \sigma_\eta(x))$}.
  \item If $\eta$ is a branch node:
    $\twopartdef  
    {H(x) = \set{(\beta, x) \mid \beta \in \beta_\eta^+}} {h(x) \geq 0}
    {H(x) = \set{(\beta, x) \mid \beta \in \beta_\eta^-}} {h(x) < 0} 
    $
  \end{enumerate}

  Retaining the notation used in Chapter \ref{chap:background}, we
  abbreviate the expression ``$z'$ is in the next node set of $z$'' by
  writing $z \yields z'$.
\end{definition}

\vspace{\baselineskip}

For any configuration $z = (\eta, x)$ for which $\eta$ is not a branch
node, $H(z)$ is just the set containing the unique next configuration
of $z$ as determined by the same rules defining next configurations
for standard BSS Machines. In the case that $\eta$ is a branch node,
there are two possibilities for $H(z)$.  If the branching function
$h_\eta$ is greater than or equal to $0$, then $H(z)$ is the set of
all pairs $(\beta, x)$, such that $x$ is unchanged, and $\beta$ is a
Yes-Node of $\eta$.  If $h_\eta(x) < 0$, then $H(z)$ is the set of
all pairs $(\beta, x)$ such that $x$ is unchanged, and $\beta$ is a
No-Node of $\eta$.

\begin{definition}{\textbf{\ndet Machine Computation}}
  
  Let $M$ be an \ndet Machine over $R$, and let $x \in \inspace_M$.
  The computation performed by $M$ on input $x$, $\compute_M(x)$ is a
  (possibly infinite) directed tree whose vertices are elements of
  $\nodes_M \times \statespace_M$.\footnote{We use the term ``vertex''
    rather than node here to avoid confusion with the nodes of the
    machine $M$ itself.}  The structure of $\compute_M(x)$ is defined
  recursively as follows:
  
  \begin{itemize}
  \item The root of $\compute_M(x)$ is the initial configuration of
    $M$ on input $x$ given by $(\eta_1, I_\infty(x))$.
    
  \item If $z$ is any vertex of $\compute_M$, and $z'$ is a
    configuration of $M$ such that $z \yields z'$, then $z'$ is a
    child vertex of $z$.\footnote{It immediately follows from this
      definition that a configuration $z$ can be a leaf of
      $\compute_M(x)$ only if it is a terminal configuration.}
  \end{itemize}
  
\end{definition}

\note{The vertices of a nondeterministic computation $\compute_M(x)$
  can be organized into levels according their distance from the
  root. Level 1 contains only the root vertex, $(\eta_1,
  I_\infty(x))$.  Level 2 contains all of the next configurations of
  $z_1$.  Level 3 contains all of the next configurations of nodes in
  Level 2, and so on.  A given configuration can appear multiple times
  in the tree and can even appear multiple times in a particular level
  if different nondeterministic paths of the same length result in the
  same configuration.}

\todo{Example}

\begin{definition}{\textbf{Halting Sub-Computation}}
  
  Let $M$ be an \ndet Machine over $R$, let $\compute_M(x)$ be the
  computation of $M$ for some input $x$, and let $z$ be 


For each leaf of $\compute_M(x)$, we define the
  \textbf{halting sub-computation}

\end{definition}

\begin{definition} \textbf{NDET-Machine Halting, Acceptance and Rejection}

  An \ndet Machine $M$ is said to \textbf{halt} on input $x$ if every
  directed path through $\compute_M(x)$ reaches a terminal
  configuration of $M$.  We use the symbol $\halting_M$ to
  denote the subset of $\inspace_M$ on which $M$ halts. \\

  An \ndet Machine $M$ is said to \textbf{accept} an input $x$ if $M$
  halts on $x$ and at least one leaf of $\compute_M(x)$ is an
  accepting configuration of $M$. If $M$ halts on $x$ and no leaf is
  labelled with an accepting configuration, we say that $M$ rejects
  $x$.
  
\end{definition}

\section{Computation Cost for  NDET Machines}

\begin{definition}{\textbf{Nondeterministic Computation Cost}}

  Let $M$ be an \ndet Machine over a ring $R$ with associated height
  function \functype{ht_R}{R}{\reals}.  Let $x \in \inspace_M$ be an
  input such that $M$ halts on $x$.  

  The \textbf{cost} of $\compute_M(x)$ is given by:
  

  Let $M$ be an NDET-Machine over a ring $R$ with height function
  $ht_R$, and let $M$ halt on input $x$.  The cost of the computation
  of $M$ on $x$ is given by:
  
  $$\max_{\compute \in \allpaths}(\cost(\compute_M(x)))$$

\end{definition}

\begin{definition} $\ndetp$
  
  A language, $S$ is in $\ndetp$ if there exists a machine $M$ and a
  constant $p$ such that, $\forall w \in S$, $M$ accepts w with cost
  $O(size(w)^p)$.
  
\end{definition}

\begin{definition} $\dtime_{f(x)}$ and $\ndettime_{f(x)}$
  A decision problem $S, S_{yes}$ is said to belong to
  $\dtime_{f(x)}$ (deterministic time $f(x)$) if there exists a BSS
  machine that decides $S$ with computation cost bounded by
  $f(size(x))$ for all $x$ in $S_{yes}$.  \\n
  
  A decision problem $S, S_{yes}$ is said to belong to
  $\ndettime_{f(x)}$ (deterministic time $f(x)$) if there exists an
  NDET machine that decides $S$ with computation cost bounded by
  $f(size(x))$ for all $x$ in $S_{yes}$.  \\
\end{definition}

\todo{Use DTIME and NDETTIME to define $\p$, $\np$, $\ndetp$, etc.}

\section{$\ndetp$ and Deterministic Complexity}

In this section we present some results relating the class $\ndetp$
with the deterministic time complexity classes described in Chapter 2.
Most of the proofs presented here are straightforward generalizations
of results from classical complexity theory.\\

Our first result generalizes the classical result that every
nondeterministic time complexity class contains its deterministic
equivalent.  This is unsurprising, since adding the power of
nondeterminism can only make computation of a problem more efficient.
As in the classical case, our proof consists in simply noting that
every deterministic machine is also a valid nondeterministic machine
that happens not to take advantage of the additional power afforded by
nondeterminism.

\todo{Is this even worth listing as a proposition, or should it just
  be a note?  If we keep it as a proposition, should the proof be made
  more formal (e.g. we could proceed by induction on the length of
  $\gamma_x$), or is this acceptable?}

\proposition{Let $R$ be a ring with any height function, and let $(S,
  S_{yes})$ be a decision problem over $R$. If $M$ is a BSS machine
  that decides $S$ in time $t(size(x))$, then $M$ also decides $S$ in
  time $t(size(x))$ when interpreted as an NDET machine.\\}

\proof{ We first note that the only difference between the definitions
  of NDET machines and standard BSS machines is that every branch node
  $\eta$ of BSS machine has a single $\beta_\eta^+$ and a single
  $\beta_{\eta}^-$, whereas each branch node of an NDET machine may
  have multiple yes and no nodes. Thus we can regard standard BSS
  machines as a special case of NDET machines for which every node has
  branching degree 1, and it makes sense to talk about interpreting
  $M$ as an NDET machine.  \\

  Let $x$ be an element of $S$, and let $M$ be a BSS machine that
  decides $S$, now interpreted as an NDET machine. Since $M$ has
  maximum branching degree 1, every configuration of $M$ has at most 1
  one valid next configuration, which implies that there is exactly
  one halting path in $\allpaths(M, x)$.  Moreover, that path is
  precisely $\compute_M(x)$, the sequence of configurations computed
  by $M$ when interpreted as a standard BSS machine.  It follows that
  $\accpaths(M, x)$ (interpreting $M$ as an NDET machine) is nonempty
  if and only if $M$ accepts $x$ when interpreted as a standard
  machine, and under either interpretation the computation cost of $M$
  on $x$ is the cost of $\compute_M(x)$.}

\corollary{Over any ring $R$ with any height function, we
  have: $$\dtime \subseteq \ndettime$$. In particular, we have: $$\p
  \subseteq \ndetp$$.}

Our next result generalizes the classical proof that any
nondeterministic Turing Machine can be simulated by a deterministic
Turing Machine with an exponential slowdown in runtime.  In light of
results from \cite{B98} showing that there are rings with cost
measures over which $\np$ contains undecidable problems, a nontrivial
corollary for us is that every problem in $NTIME_{f(x)}$ is decidable.

\proposition{Let $R$ be a ring with any height function, and let $(S,
  S_{yes})$ be a decision problem over $R$.  If $M$ is an NDET Machine
  that decides $S$ with cost bounded by $t(size(x))$ for all $x$ in
  $S$, then there exists a standard BSS machine, $M'$ that decides $S$
  in time $O(d^{t(size(x))})$, where $d$ is the maximum branching degree of
  any node in $M$.}

\proof{ Algorithm \ref{alg:Simulate-NDET} uses the existence of the
  NDET machine $M$ to decide $S$ with the given bound.  The
  essential idea is that on input $x$ we can breadth-first search
  through the configuration space of $M$, checking all possible
  paths of length less than $t(size(x))$.

  \begin{algorithm} 
    \caption{Simulate-NDET} \label{alg:Simulate-NDET}
    \begin{algorithmic}
      \Require $x \in R_\infty$
      \State $i = 0$
      \State $maxpaths = t(size(x))$
      \State Add configuration $(x, \eta_1)$ to $queue$
      \While{True}
      \State $z$ = $queue.next()$
      \State $i = i+1$
      \If{$i$ > $pathMax$} 
      \State \textbf{reject}
      \EndIf
      \State compute $H_M(z)$
      \For{configuration $(x, \eta)$ in $H_M(z)$} 
      \If{$\eta$ = $\eta_{accept}$}
      \State \textbf{accept}
      \Else add $(x, \eta)$ to $queue$
      \EndIf
      \EndFor
      \EndWhile
    \end{algorithmic}
  \end{algorithm}}  

\todo{Runtime analysis of queue implementation.}

Since every node in $M$ has branching degree $d$ or less, there are
at most $d$ valid next configurations succeeding any configuration,
$z$.  Thus there are at most $d^{t(size(x))}$ paths of length
$t(size(x))$.  In the worst case, which occurs whenever we reject,
we search all such paths, so our worst case runtime is
$O(d^{t(size(x))})$.

\corollary{For any ring $R$ and any cost measure, $\ndettime_{f(x)}
  \subseteq \exptime$}

\corollary{Every problem decidable by an NDET machine is decidable in
  the standard BSS sense.}

The above results shows that nondeterminism does not grant us any more
power as far as computability goes; it ``merely'' gains us at most an
exponential decrease in runtime for decision algorithms.  While this
agrees with the classical case, we note that it is not true in general
for $\np$ over all rings and cost functions.

\section{$\ndetp$ and $\np$}

We now wish to consider the relationship between the $\ndetp$ and the
$\np$ as it has been developed by Blum et al and others.  Since these
classes generalize notions that are equivalent in the classical model,
the natural question to ask is whether the equivalence holds in the
generalized model.  Blum et al. show in \cite{B89} that $\parg{\Z{2}}$
with unit cost and $\parg{\integers}$ are both equivalent to the
classical $\p$, with similar results obtaining for the analogous
$\mathbf{NP}$ classes.  Thus we expect that $\ndetp$ and $\np$ should
coincide for $R = \Z{2}$.  We prove the slightly more general result
that $\ndetp = \np$ for any ring $R$ with height function $ht_R$ such
that, for any $k \in R$ there are at most finitely many elements of
$R$ Our proof follows the classical case by showing that $\ndetp$
machines can match the computational power of $\np$ machines by simply
generating all possible witnesses.  This argument depends crucially on
the fact that for a finite ring there can be at most exponentially
many witnesses of a given length.  Since this is no longer the case
for infinite rings, it becomes less clear under what conditions the
equality still holds.

\todo{Better transition.}

\theorem{When considered with unit cost, $\nparg{\integers}
  \not\subset \decarg{\integers}$}

\proof{ It is easy to formulate Hilbert's Tenth Problem, which asks if
  an arbitrary diophantine equation has solutions over the integers,
  as a decision problem over $\integers$ It is also easy to show that
  this problem is in $\np$, since a witness for a solvable diophantine
  equation is the solution in queston. Since it is well known that
  Hilbert's Tenth Problem is undecidable we have our desired result.
  For more details see \cite{B98}, Chapter 6.}

The above result shows that the classical equivalence of efficient
verifiability and nondeterministic computability is not necessarily
valid for rings other than $\integers_2$.  Two natural questions
arise concerning the relationship between $\ndetp$ and $\np$.  

\begin{itemize}
\item Is it always the case that $\ndetp \subseteq \np$.
\item Under what circumstances is it the case that $\ndetp = \np$?
\end{itemize}

We give an affirmative answer to the first question.  This is
because, given an NDET Machine $M$ that decides a set $S$, we can
produce an NP Machine $M'$ that also decides $S$ by labelling each
node in $M$ by a unique value (or series of values if necessary)
from $R$ and replacing each branch node of $M$ with a subroutine
that reads the next unread value in the witness $w$, and transitions
to the node labelled by that integer if it is a valid next node for
the current configuration. For such a machine, an accepting witness
is one that encodes the sequence of nondeterministic choices made by
$M$ on some accepting path.

\theorem{Let $S$ be a decision problem over a ring $R$ with height
  function $ht_R$, and let $M$ be an NDET machine that decides $M$ in
  time bounded by $O(T(\size(x)))$.  Then there exists an NP machine,
  $M'$ which also decides $S$ in time $O(T(\size(x)))$}

\todo{I think this might work better written out in algorithm style
  like the one above.  Also, should the statement about assuming
  branching degree 2 be broken out into a Lemma?}

\proof{Let $S$ and $M$ be as stated above.  We assume without loss of
  generality that $M$ has maximum branching degree 2, since we can
  always replace a branch node of higher branching degree with a chain
  of branch nodes of degree 2, and doing so increases the runtime of
  $M$ by at most a multiplicative constant factor of $d$.  We
  construct the NP machine $M'$ by starting with $M$ and replacing
  each branch node $\eta$ of $M$ with a subroutine that first computes
  the branching check associated with $\eta$, then queries the witness
  string $w$ and decides which of the possible next nodes to
  transition into based on the value stored in the first coordinate of
  $w$.}

Toward answering the second question, we show that a sufficient
condition for $\ndetp = \np$ is that all values in $R^\infty$ of
size $s$ or less be enumerable by an NDET machine in
nondeterministic time $O(log s)$.  We conjecture that this condition
is also sufficient.  

\theorem{Let $R$ be a ring with associated height function
  satisfying the property that there exists an NDET Machine that
  enumerates every value in $R^\infty$ with size at most $s$ in
  nondeterministic time $O(\log s)$.

  \proof{
    Let $S \in \np$.  Then there exists a machine $M$ such that for
    every $x$ in $S$ there exists a $w$ such that $\computefn_M(x, w)
    = 1$ and $cost_M(x, w) \leq p(size(x))$, where p is some
    polynomial function.  It immediately follows that $w$ must have
    size less than $p(size(x))$, or else computing a single step with
    $w$ in a register of $\statespace_M$ would render the cost of
    computing a single step to be greater than the given bound on the
    runtime of $M$.  Thus we can construct an NDET-Machine which, on
    input $x$, nondeterministically generates all possible witnesses
    of length at most $p(size(x))$, and then for each possible witness
    $w$ simulates $M$ on input $w$.
  }

\todo{Section on digital nondeterminism equivalence and DNP-Complete problems.}


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "main"
%%% End: 
